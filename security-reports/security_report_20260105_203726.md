# Security Vulnerability Report

**Target:** `C:\Users\texas\Tesseract\Tesseract\src`
**Scan Date:** 2026-01-05 20:37:32
**Files Scanned:** 83
**Scan Duration:** 511.27 seconds

---

## Executive Summary

ðŸ”´ **Overall Risk Level: CRITICAL**

The security scan identified **33 potential vulnerabilities** in the codebase:

| Severity | Count |
|----------|-------|
| ðŸ”´ Critical | 4 |
| ðŸŸ  High | 5 |
| ðŸŸ¡ Medium | 16 |
| ðŸŸ¢ Low | 8 |
| âšª Info | 0 |

**Immediate action recommended for 9 critical/high severity issues.**

## Scan Statistics

### Findings by Tool
| Tool | Findings |
|------|----------|
| gemini-ai | 33 |

### Top CWE Categories
| CWE | Count | Description |
|-----|-------|-------------|
| CWE-329 | 2 | Security Weakness |
| CWE-287 | 2 | Security Weakness |
| CWE-354 | 2 | Security Weakness |
| CWE-316 | 2 | Security Weakness |
| CWE-327: Use of a Broken or Risky Cryptographic Algorithm | 2 | Security Weakness |


## Findings by Severity

### ðŸ”´ Critical (4)

#### 1. Critical Nonce Reuse in `EncryptedAllocation::write`

- **Location:** `memory\pool.rs` (lines 282-311)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-329

**Description:**
The `EncryptedAllocation::write` method can be called multiple times on the same allocation object. Each time it is called, it re-initializes the ChaCha20 cipher with the same key and the same nonce that was generated when the allocation was created. Reusing a nonce with a stream cipher is a catastrophic cryptographic failure. If an attacker can observe the ciphertext from two separate `write` operations on the same allocation, they can compute the XOR of the two plaintexts (`C1 âŠ• C2 = P1 âŠ• P2`), which can lead to the full recovery of both plaintexts.

**Remediation:**
The design must prevent nonce reuse. The most robust solution is to generate a new, random nonce for every call to `write`. This new nonce must be stored with the ciphertext (e.g., by prepending it) and used for the corresponding `read` operation. Alternatively, if overwriting is not an intended feature, the `EncryptedAllocation` should track if it has been written to and return an error on subsequent `write` calls.

#### 2. Unauthenticated Remote Wipe Command Execution

- **Location:** `volume\cloud_sync.rs` (lines 934-952)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-345

**Description:**
The remote wipe command mechanism lacks cryptographic verification. Wipe commands are stored as JSON objects in a predefined location in cloud storage. An attacker with write access to the cloud storage bucket can craft and upload a malicious `WipeCommand` JSON object. When a client application syncs, it will download, deserialize, and execute this command without verifying its authenticity. This allows an attacker to trigger a remote wipe (data destruction) or lock a volume without authorization. The command is filtered by `volume_id`, but this ID is stored in the manifest, which is likely accessible to the same attacker.

**Remediation:**
Implement cryptographic signing for all `WipeCommand` objects.
1.  Generate a signing key pair (e.g., Ed25519) for the entity authorized to issue wipe commands. The public key should be securely distributed to clients, possibly during volume setup.
2.  When creating a `WipeCommand`, sign the command data and include the signature within the `WipeCommand` struct.
3.  In the `check_for_wipe_commands` function, before returning or processing any command, verify its signature against the known public key. Discard any command with an invalid signature.

#### 3. Incorrect Password Used for Mounting Hidden Volumes

- **Location:** `volume\manager.rs` (lines 254-255)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-287

**Description:**
When mounting a hidden volume, the `mount` function correctly uses the hidden volume password to open and verify the hidden volume metadata (line 246). However, for the actual mount operation that decrypts the filesystem, it incorrectly prepares and uses the *outer* volume's password. The `mount_password` variable is assigned the value of the original `password` parameter (the outer volume's password) on line 254, and this incorrect password is then passed to the `super::mount::mount` function on line 265. This will either cause the mount to fail or, in a worst-case scenario, lead to data corruption if the mount process proceeds with incorrect decryption keys. This flaw defeats the security separation between the outer and hidden volumes.

**Remediation:**
When mounting a hidden volume, ensure that the hidden volume's password is used for the final mount operation. Modify the logic to pass the `hidden_pwd` to the `mount` call.

```rust
// In lines 234-262, change this part:
                (
                    container_path.clone(),
                    hidden_size,
                    true,
                    password.to_string(),
                )
// To this:
                (
                    container_path.clone(),
                    hidden_size,
                    true,
                    hidden_pwd.to_string(), // Use the hidden password for mounting
                )
```

#### 4. Incorrect Implementation of AWS Signature V4 Using BLAKE3 Instead of HMAC-SHA256

- **Location:** `volume\s3_client.rs` (line 395)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-327 (Use of a Broken or Risky Cryptographic Algorithm)

**Description:**
The implementation of AWS Signature V4 is fundamentally flawed. It incorrectly uses the BLAKE3 hashing algorithm for multiple critical steps where the AWS standard explicitly requires SHA256 and HMAC-SHA256.
1.  On line 395, `blake3::hash` is used to compute the payload hash (`x-amz-content-sha256`), but the standard requires SHA256.
2.  On line 414, `blake3::hash` is used to hash the canonical request, but the standard requires SHA256.
3.  The `hmac_sha256` function (lines 477-488) does not compute HMAC-SHA256. Instead, it uses BLAKE3's keyed hashing mode, which is a different algorithm. This is used for the entire signature derivation chain in `calculate_signature` (lines 457-464).

This non-standard implementation will produce signatures that are invalid and will be rejected by AWS S3 and compliant services. The function name `hmac_sha256` is dangerously misleading. The comment on line 456 (`Note: This is a simplified version. Production should use proper HMAC-SHA256`) confirms the implementation is not correct for production use.

**Remediation:**
The entire signing process must be rewritten to conform to the AWS Signature V4 standard.
1.  Replace `blake3::hash` with a standard SHA256 implementation (e.g., from the `sha2` crate) for hashing the payload (line 395) and the canonical request (line 414).
2.  Replace the custom `hmac_sha256` function with a proper HMAC-SHA256 implementation using standard crates like `hmac` and `sha2`.
3.  Update the `calculate_signature` function (lines 457-464) to use the correct HMAC-SHA256 function for each step of the key derivation and final signing process.

### ðŸŸ  High (5)

#### 1. Use of a Static, All-Zero Nonce in AES-GCM Benchmark Functions

- **Location:** `crypto\hardware.rs` (lines 784-785)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-330

**Description:**
The benchmark functions `benchmark_aes_gcm` and `benchmark_aes_gcm_decrypt` use a hardcoded, static, all-zero nonce for all AES-GCM encryption and decryption operations within the benchmark loop. In AES-GCM, reusing a (key, nonce) pair is a critical cryptographic vulnerability. It completely destroys confidentiality by allowing an attacker to recover the authentication key (GHASH key), which in turn allows them to forge arbitrary messages. It also leaks information about the plaintext.

While a comment on line 784 acknowledges this is for benchmarking only, providing example code that contains a critical cryptographic anti-pattern is highly dangerous. Developers may copy this benchmark code for use in production applications without fully understanding the severe security implications of nonce reuse. Cryptographic libraries should provide examples that follow security best practices to avoid accidental misuse.

**Remediation:**
To maintain benchmark determinism while demonstrating correct nonce handling, modify the benchmark to use a unique nonce for each iteration. A simple counter-based approach is suitable for this purpose. Instead of using a static nonce, create a mutable nonce and increment it inside the loop.

For example, in `benchmark_aes_gcm`:
```rust
// Before the benchmark loop
let mut nonce_bytes = [0u8; 12];

// ...

// Inside the benchmark loop
let start = Instant::now();
for i in 0..iterations {
    // Increment the nonce for each encryption to avoid reuse.
    // This is a simple counter-based approach suitable for a benchmark.
    // It correctly demonstrates the principle of never reusing a nonce.
    nonce_bytes[0..4].copy_from_slice(&(i as u32).to_le_bytes());
    let nonce = Nonce::from(nonce_bytes);
    let _ = cipher.encrypt(&nonce, plaintext.as_ref());
}
```
Apply a similar change to the `benchmark_aes_gcm_decrypt` function, ensuring the nonce used for decryption matches the one used for encryption in the setup phase for each corresponding iteration if the ciphertext is pre-generated outside the loop. A simpler fix for the decrypt benchmark is to generate the ciphertext inside the loop using the incrementing nonce.

#### 2. Plaintext Written to Output Before Final Integrity Verification

- **Location:** `crypto\streaming.rs` (lines 1544-1554)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-354

**Description:**
The `decrypt_to_parallel` function decrypts chunks of data and immediately writes the resulting plaintext to the output `writer` within the processing loop. A final integrity check is performed at the end of the function (line 1552) to ensure the total number of bytes written matches the `original_size` specified in the stream's header.

This creates a "check-after-write" vulnerability. An attacker can craft a truncated encrypted stream by simply omitting chunks from the end. The function will successfully decrypt and write the initial, valid chunks to the output stream. When the input stream ends prematurely, the loop will terminate, and the final size check will fail, returning an error. However, by this point, the partial, unverified plaintext has already been written to the destination.

If the calling application does not meticulously handle the error and atomically delete the partially written output, it may be left with a truncated and potentially malicious file that it might later trust or process. This violates the atomicity principle of authenticated decryption, where no plaintext should be considered valid until the entire ciphertext is verified.

**Remediation:**
Do not write decrypted data to the final destination until the entire stream has been processed and all integrity checks have passed.

One common and robust solution is to write the decrypted plaintext to a temporary file or an in-memory buffer. After the loop completes and the final size check on line 1552 succeeds, the temporary file can be atomically moved/renamed to the final destination path, or the buffer can be flushed to the output writer. If the final check fails, the temporary file or buffer is simply discarded, ensuring that no invalid partial data is ever present at the final destination.

#### 3. Ineffective Crash Dump Protection on Windows

- **Location:** `memory\dump_protection.rs` (lines 127-139)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-693

**Description:**
The `disable_crash_dumps` function is intended to prevent the creation of crash dumps, which could contain sensitive in-memory information like cryptographic keys or personal data. However, on the Windows platform (`cfg(not(unix))`), the function is a no-op and immediately returns a `NotSupported` error. This fails to provide the advertised security protection. An application developer relying on this function for security on Windows would have a false sense of security, leaving sensitive data vulnerable to exposure through crash dumps (e.g., via Windows Error Reporting). While the function correctly signals an error, the existence of an API with this name implies functionality that is critically missing for a major target platform.

**Remediation:**
Implement crash dump protection on Windows. This can be achieved using the Win32 API. A common approach is to call `SetErrorMode` with the `SEM_NOGPFAULTERRORBOX` flag to suppress the crash dialog. For more robust protection against Windows Error Reporting (WER), use the `WerAddExcludedApplication` function to prevent WER from creating dumps for the application. If a full implementation is not immediately feasible, the function should be marked as deprecated on Windows with a compile-time warning that clearly states the lack of protection.

#### 4. CSP Injection via Unsanitized Whitespace in `additional_sources`

- **Location:** `wasm\security.rs` (lines 127-133)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-79

**Description:**
The `generate_csp_header` function attempts to sanitize additional script sources to prevent CSP injection. The validation logic on line 127 checks for spaces (`' '`), newlines, and carriage returns, but fails to check for other whitespace characters, such as tabs (`\t`). An attacker can provide a source string containing a tab, like `"example.com\tmalicious.com"`, which will bypass the validation. When this string is included in the `script-src` directive, the browser will interpret the tab as a separator, effectively injecting `malicious.com` as a trusted script source. This undermines the protection offered by the Content Security Policy, potentially allowing Cross-Site Scripting (XSS) attacks from the injected domain.

**Remediation:**
Modify the validation logic to reject any whitespace characters, not just spaces. A robust way to do this is to check if the source string contains any character that is considered whitespace.

```rust
// Before
if !source.contains(';')
    && !source.contains('\n')
    && !source.contains('\r')
    && !source.contains(' ')
{
    script_src.push(source);
}

// After (Recommended)
if !source.chars().any(char::is_whitespace) && !source.contains(';') {
    script_src.push(source);
}
```
The `char::is_whitespace` method covers spaces, tabs, newlines, and other Unicode whitespace characters, providing a more comprehensive defense against injection.

#### 5. Privilege Escalation due to Insecure Relative Path Resolution

- **Location:** `bin\register\mod.rs` (lines 18-32)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-426: Untrusted Search Path

**Description:**
The `get_gui_exe_path` function determines the path to the `tesseract-gui` executable by assuming it is in the same directory as the `tesseract-register` executable itself. This utility is intended to modify system-wide settings (file associations, registry keys), which typically requires elevated privileges (e.g., running via `sudo` or as an Administrator).

If a privileged user is tricked into running `tesseract-register` from a directory that is writable by a non-privileged attacker (e.g., `/tmp/` or a user's home directory), the application will trust and register a potentially malicious `tesseract-gui` executable placed in that same directory by the attacker.

This allows a low-privileged attacker to configure the system to execute their malicious code whenever any user (including an administrator) opens a file associated with Tesseract, leading to arbitrary code execution and privilege escalation.

**Remediation:**
The installer should not trust executables located in a potentially untrusted, relative path when running with elevated privileges.

1.  **Use a fixed, secure location:** Modify the installer to place the `tesseract-gui` executable in a protected, system-wide directory during a proper installation process (e.g., `C:\Program Files\` on Windows, `/usr/bin/` or `/opt/` on Linux). The `get_gui_exe_path` function should then be hardcoded to point to this secure, absolute path.

2.  **Verify directory permissions:** If using a relative path is a strict requirement, the application must verify the security of the execution environment before proceeding with privileged operations. Before registering the executable, check that the parent directory is owned by a privileged user (e.g., `root`) and is not writable by unprivileged users. If the checks fail, abort the installation.

### ðŸŸ¡ Medium (16)

#### 1. Excessive Information in Error Messages Can Leak Sensitive Data

- **Location:** `error.rs` (lines 15-64)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-209

**Description:**
The `CryptorError` enum is designed in a way that can leak sensitive internal information when errors are displayed or logged. Several variants either wrap underlying error types that contain sensitive data or use a generic `String` which encourages the inclusion of detailed, potentially sensitive, information.

Specifically:
1.  **Path Disclosure**: The `Io(#[from] std::io::Error)` (line 18) and `TempFilePersist(#[from] tempfile::PersistError)` (line 47) variants automatically convert from underlying error types that often include full file paths in their string representation. Exposing these paths reveals information about the file system structure, usernames, and application layout, which can aid an attacker in further exploitation.
2.  **Cryptographic Detail Leakage**: Variants like `Cryptography(String)` (line 25), `PasswordHash(String)` (line 29), `Argon2(String)` (line 34), and `KeyDerivation(String)` (line 54) use a raw `String` to convey error details. This can lead to leaking low-level cryptographic error messages (e.g., "invalid padding", "MAC verification failed"). Such detailed information can provide an oracle for sophisticated attacks, such as padding oracle attacks, which can lead to plaintext recovery. The `Decryption` variant (line 38) correctly uses a generic message to avoid this, but this best practice is not applied consistently.

**Remediation:**
Refactor the `CryptorError` enum to avoid including sensitive details in its user-facing `Display` implementation. Internal details needed for debugging should be logged separately and not exposed in messages that a user might see.

1.  For variants that wrap other errors (like `Io` and `TempFilePersist`), implement the `From` trait manually instead of using `#[from]`. In the `Display` implementation (`#[error(...)]`), provide a generic message. The original error can be stored in a `source` field for internal logging.

    Example for `Io`:
    ```rust
    // In CryptorError enum
    #[error("An I/O error occurred")]
    Io {
        #[source]
        source: std::io::Error,
    },

    // Manual implementation
    impl From<std::io::Error> for CryptorError {
        fn from(err: std::io::Error) -> Self {
            CryptorError::Io { source: err }
        }
    }
    ```

2.  For `String`-based variants, replace them with specific, structured enum variants that don't carry arbitrary strings. The `Display` implementation for these new variants should be a fixed, safe message.

    Example for `Cryptography`:
    ```rust
    // Replace Cryptography(String) with a more structured type
    #[error("A cryptographic operation failed")]
    Cryptography(#[from] CryptoError),
    
    // ... define a new error enum for crypto details
    #[derive(Error, Debug)]
    pub enum CryptoError {
        #[error("Invalid padding")] // This message is for internal logging
        InvalidPadding,
        #[error("MAC verification failed")] // This message is for internal logging
        MacVerificationFailed,
        // etc.
    }
    ```
    When a `CryptorError::Cryptography` is displayed, it will only show "A cryptographic operation failed". The more specific `CryptoError` can be accessed via the `source()` method for detailed, internal-only logging.

#### 2. Hardcoded Weak Password in Test Case

- **Location:** `crypto\pqc_tests.rs` (line 250)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-798

**Description:**
The test case `test_hybrid_mode_full_flow` uses a hardcoded password, `b"TestPassword123!"`, to derive a key using Argon2. Hardcoding credentials, even in test files, is a significant security risk. This practice sets a poor precedent for developers, who may copy this pattern into production code. If the source code is ever exposed, it reveals password patterns or the exact credentials, which could be reused across different systems. Furthermore, test environments are sometimes connected to staging or even production systems, making hardcoded credentials in tests a potential entry point for attackers.

**Remediation:**
Do not hardcode passwords or other secrets in source code. For this test case, generate a random, high-entropy byte string at the beginning of the test to serve as the password. This ensures the test is reproducible in its logic without exposing a static secret.

Example:
```rust
use rand::RngCore;

// ... inside the test function ...
let mut password = [0u8; 32];
rand::thread_rng().fill_bytes(&mut password);

let kdf = Argon2Kdf::default();
let salt = kdf.generate_salt();
let classical_key = Zeroizing::new(kdf.derive_key(&password, &salt).unwrap());
```

#### 3. Authentication Token Clone Not Zeroized in Memory

- **Location:** `daemon\client.rs` (line 177)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-316

**Description:**
In the `send_command_impl` function, the authentication token is cloned to be passed to the `AuthenticatedRequest` struct: `AuthenticatedRequest::new(token.clone(), command)`. This cloned `String` containing the secret token is not cleared from memory after it has been serialized and sent to the daemon. When the `request` variable goes out of scope, the memory holding the cloned token is deallocated but not overwritten. An attacker with the ability to read the client process's memory could potentially recover this sensitive token. While the main `DaemonClient` struct correctly zeroizes its copy of the token on drop, this temporary clone is missed, leaving a window where the secret is exposed in memory.

**Remediation:**
The `AuthenticatedRequest` struct should be modified to store the authentication token in a wrapper that automatically zeroizes its contents when dropped, such as `zeroize::Zeroizing<String>`. This ensures that all copies of the token are securely erased from memory as soon as they are no longer needed. If modifying `AuthenticatedRequest` is not feasible, the cloned token should be explicitly zeroized within the `send_command_impl` function after it has been used for serialization.

#### 4. Insecure Default Configuration for HSM

- **Location:** `hsm\mod.rs` (lines 87-93)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-1188: Insecure Default Initialization of Resource

**Description:**
The `HsmConfig::default()` implementation provides an insecure-by-default configuration. It sets `require_device` to `false` and `allow_backup` to `true`. This means that unless a developer explicitly overrides these settings, the hardware security module will not be enforced, and a potentially weaker backup mechanism will be allowed. This could lead to an attacker bypassing the intended hardware-based security controls in applications that use this default configuration. Security-critical configurations should default to the most secure settings (fail-safe defaults).

**Remediation:**
Change the default `HsmConfig` to enforce security. Set `require_device` to `true` and `allow_backup` to `false` by default. Developers who need a less strict configuration can then explicitly opt-out.
```rust
impl Default for HsmConfig {
    fn default() -> Self {
        Self {
            require_device: true,
            allow_backup: false,
            max_attempts: 3,
            timeout_ms: 5000,
        }
    }
}
```

#### 5. Use of Weak Cryptographic Algorithm (HMAC-SHA1)

- **Location:** `hsm\mod.rs` (line 10)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-327: Use of a Broken or Risky Cryptographic Algorithm

**Description:**
The documentation comment on line 10 indicates that the YubiKey integration uses "HMAC-SHA1 challenge-response". The SHA-1 algorithm is considered cryptographically weak and has been deprecated for most uses since 2011 due to practical collision attacks. While HMAC-SHA1 is not as vulnerable as plain SHA-1, it is still based on a weak primitive. Security standards (like NIST SP 800-131A) recommend phasing out SHA-1 in favor of stronger algorithms from the SHA-2 or SHA-3 families (e.g., SHA-256). Using HMAC-SHA1 reduces the security margin and may not comply with modern security requirements.

**Remediation:**
Migrate the YubiKey challenge-response mechanism to use a stronger algorithm, such as HMAC-SHA256. Update the YubiKey configuration and the corresponding implementation in the `yubikey` module to support and default to the stronger algorithm.

#### 6. Support for Broken Cryptographic Algorithm (SHA-1)

- **Location:** `hsm\tpm.rs` (line 1667)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-327: Use of a Broken or Risky Cryptographic Algorithm

**Description:**
The library supports the SHA-1 hash algorithm for TPM operations, as confirmed by the test on line 1667 within the `test_sealed_blob_serialization_all_hash_algorithms` function. SHA-1 is a legacy algorithm that is considered cryptographically broken and is susceptible to practical collision attacks. Exposing this option in the API increases the risk that developers will inadvertently use it for security-critical operations like policy digests, leading to insecure configurations that undermine the security guarantees of the TPM. While the default algorithm is a secure SHA-256, providing a known-weak option is a security anti-pattern.

**Remediation:**
It is strongly recommended to deprecate and remove support for `TpmHashAlgorithm::Sha1` from the library's public API. If it must be retained for backward compatibility with legacy systems, its use should be clearly documented as insecure and should ideally trigger a compile-time or run-time warning to discourage its use.

#### 7. Use of a Cryptographically Weak Hashing Algorithm (SHA-1)

- **Location:** `hsm\tpm_utils.rs` (line 40)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-327

**Description:**
The code defines, and provides conversion functions for, the SHA-1 hashing algorithm (`TPM_ALG_SHA1`). SHA-1 is considered cryptographically broken for collision-resistance and should not be used in new security-sensitive applications. While some legacy TPM operations may require SHA-1, its inclusion in this utility library without explicit warnings or restrictions facilitates its use in contexts where it is insecure, such as for policy digests or signature verification. An application developer using this library might inadvertently select SHA-1, leading to a system that is vulnerable to collision attacks.

**Remediation:**
1.  Remove support for `TpmHashAlgorithm::Sha1` from the enum and the conversion functions (`hash_algorithm_to_tpm_alg`, `tpm_alg_to_hash_algorithm`).
2.  If SHA-1 support must be maintained for legacy compatibility (e.g., for interacting with specific PCR banks that only support SHA-1), the `TpmHashAlgorithm::Sha1` variant should be marked as deprecated with a clear warning about its cryptographic weaknesses.
    ```rust
    // In the TpmHashAlgorithm enum definition
    #[deprecated(since = "x.y.z", note = "SHA-1 is cryptographically weak and should not be used for new applications.")]
    Sha1,
    ```
3.  Additionally, add documentation to the `hash_algorithm_to_tpm_alg` function explaining the risks of using SHA-1 and guiding users to stronger alternatives like SHA-256.

#### 8. Unenforced YubiKey Serial Number Allows Device Spoofing

- **Location:** `hsm\yubikey.rs` (line 93)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-287

**Description:**
The `YubiKeyConfig` struct includes a `serial` field, which allows a user to specify the serial number of a particular YubiKey to use. This gives the impression that the application can be locked to a specific hardware token. However, the implementation in the `challenge_response` function calls `yubi.find_yubikey()` without using the configured serial number. The `find_yubikey()` function from the underlying `yubikey-hmac-otp` crate simply finds the first available YubiKey device. This discrepancy means that any YubiKey programmed with the correct secret will be accepted, even if a specific serial number was configured, bypassing the intended device pinning. An attacker could substitute the user's YubiKey with a different one (e.g., a clone or another device they control with the same secret) to successfully authenticate.

**Remediation:**
The device discovery logic must be updated to honor the `serial` number configuration. If the current `yubikey-hmac-otp` crate does not support device discovery by serial number, consider switching to a more feature-rich crate like `yubikey` that allows enumerating all devices and selecting one by its serial number. If this is not possible, remove the `serial` field from `YubiKeyConfig` and clearly document that the implementation will use any available YubiKey to avoid providing a false sense of security.

#### 9. Use of Deprecated and Potentially Insecure Random Number Generator API

- **Location:** `hsm\yubikey_stub.rs` (line 146)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-338

**Description:**
The function `generate_backup_key` uses `rand::rng()`, which is a deprecated API from old versions of the `rand` crate (specifically, version 0.4 or earlier, as the function was removed in 0.5). Relying on such an old version of a critical cryptographic dependency is risky, as it will not receive security patches and may itself depend on other outdated libraries with known vulnerabilities (e.g., older versions of the `getrandom` crate). While `rand::rng()` in version 0.4 was intended to be a Cryptographically Secure Pseudo-Random Number Generator (CSPRNG), using a modern, maintained version is crucial for ensuring cryptographic security and avoiding known vulnerabilities.

**Remediation:**
Update the `rand` crate dependency to the latest stable version in the project's `Cargo.toml`. Modify the code to use the modern, recommended API for acquiring a thread-local CSPRNG.

Replace this line:
`rand::rng().fill_bytes(&mut key);`

With this:
`rand::thread_rng().fill_bytes(&mut key);`

You will also need to ensure `rand::RngCore` is in scope, which is already satisfied by the `use` statement on line 144.

#### 10. Use of Unauthenticated Encryption

- **Location:** `memory\pool.rs` (lines 36-37)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-354

**Description:**
The code uses the ChaCha20 stream cipher directly for encryption. Stream ciphers do not provide any data integrity or authenticity guarantees. An attacker with the ability to modify the encrypted data in memory (e.g., via another vulnerability or with physical access) can perform bit-flipping attacks. Flipping a bit in the ciphertext will cause the corresponding bit to be flipped in the decrypted plaintext. The application will not be able to detect that the sensitive data has been tampered with, which could lead to severe consequences depending on how the data is used.

**Remediation:**
Use an Authenticated Encryption with Associated Data (AEAD) cipher instead of a plain stream cipher. `ChaCha20Poly1305` is an excellent choice that combines the ChaCha20 cipher with the Poly1305 message authentication code (MAC). This would require storing the authentication tag alongside the ciphertext and verifying it during decryption. The `aead` crate in Rust provides a convenient interface for this.

#### 11. Sensitive Password Data Exposed in Memory

- **Location:** `volume\automount.rs` (line 292)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-316 (Cleartext Storage of Sensitive Information in Memory)

**Description:**
The `mount_with_password` function accepts a password as a `&str`. Standard string types in Rust are not guaranteed to be securely erased from memory after use. This leaves the sensitive password lingering in the application's memory, where it could be exposed through memory dumps, swapped to disk, or accessed by other processes with sufficient privileges. The password is then passed to the `volume_manager.mount` function, propagating the issue.

**Remediation:**
Use a dedicated secret-handling type that securely zeroes its memory when it's no longer needed. The `secrecy` crate is a popular choice, providing types like `SecretString`. The function signature should be changed to `pub fn mount_with_password(&mut self, volume_id: &str, password: &SecretString) -> Result<()>` and the internal call to the volume manager should expose the secret only for the duration of its use.

#### 12. Path Traversal in Dropbox Path Prefix

- **Location:** `volume\dropbox_client.rs` (lines 105-118)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-22

**Description:**
The `DropboxConfig::new` function constructs a `path_prefix` from a user-provided string. The function normalizes the path to ensure it starts and ends with a forward slash but does not sanitize or validate the input to prevent path traversal sequences (e.g., `..`). An attacker who can control the `path_prefix` configuration value could provide a malicious path like `/intended/path/../../sensitive/`, causing the application to construct API requests that target files outside of the intended directory within the user's Dropbox account. While the Dropbox API server may reject such paths, relying on server-side validation is not sufficient. This could lead to unintentional reading, writing, or deletion of files in other parts of the user's Dropbox, depending on the permissions of the OAuth2 token.

**Remediation:**
Implement input validation within the `DropboxConfig::new` function. Check for and reject any `path_prefix` that contains `..` as a path component. Alternatively, normalize the path by resolving all `.` and `..` components before storing it. A simple way to prevent this is to reject the configuration if the string contains `"/../"` or starts with `../`.

#### 13. Uncontrolled Memory Allocation via Deserialization Leading to Denial of Service

- **Location:** `volume\header.rs` (lines 647-648)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-770

**Description:**
The function `PqVolumeMetadata::read_from` takes a `size` parameter, which is read from the untrusted `VolumeHeader`'s `pq_metadata_size` field. This `size` is used directly to allocate a vector: `let mut bytes = vec![0u8; size as usize];`. An attacker can craft a volume file with a header containing a large value for `pq_metadata_size` (up to `u32::MAX`, which is ~4GB). When the application attempts to read the post-quantum metadata, this will trigger a massive memory allocation, likely causing the process to crash due to an out-of-memory error, resulting in a Denial of Service (DoS).

**Remediation:**
Before allocating the vector, validate the `size` parameter against a reasonable upper bound. The existing constant `MAX_PQC_METADATA_SIZE` (67072 bytes) is designed for this purpose and should be used as the limit.

```rust
// In PqVolumeMetadata::read_from
pub fn read_from<R: Read>(reader: &mut R, size: u32) -> Result<Self, HeaderError> {
    // Add this check to prevent excessive memory allocation
    if size as usize > MAX_PQC_METADATA_SIZE {
        return Err(HeaderError::SizeMismatch {
            expected: MAX_PQC_METADATA_SIZE,
            actual: size as usize,
        });
    }
    let mut bytes = vec![0u8; size as usize];
    reader.read_exact(&mut bytes)?;
    Self::from_bytes(&bytes)
}
```
This change ensures that the application will not attempt to allocate an unreasonable amount of memory, mitigating the DoS vulnerability.

#### 14. Naive URL Parsing May Lead to Server-Side Request Forgery (SSRF)

- **Location:** `volume\s3_client.rs` (lines 138-151)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-918 (Server-Side Request Forgery (SSRF))

**Description:**
The `host` function parses the host from a custom endpoint URL using simple string manipulation (`trim_start_matches`, `split`, `next`). This parsing logic is not robust enough to handle complex or maliciously crafted URLs. If an attacker can influence the `endpoint` configuration value, they could provide a URL that tricks the parser into extracting an unintended hostname. For example, an attacker could specify an endpoint that points to an internal service (`http://169.254.169.254/latest/meta-data` or `http://internal-service.local/api`). The application would then send signed requests to this internal service, potentially leading to information disclosure or other unauthorized actions. The vulnerability's impact depends on the deployment environment and the ability of an attacker to modify the S3 configuration.

**Remediation:**
Use a robust, well-tested URL parsing library to handle endpoint URLs. Replace the manual string manipulation in the `host` function with calls to a library like `url`.

Example using the `url` crate:
```rust
// In Cargo.toml:
// url = "2.5"

// In s3_client.rs
use url::Url;

// ... inside S3Region::host
pub fn host(&self, bucket: &str) -> String {
    if let Some(ref endpoint) = self.endpoint {
        // Use a proper URL parser
        Url::parse(endpoint)
            .ok()
            .and_then(|u| u.host_str().map(|s| s.to_string()))
            .unwrap_or_else(|| "localhost".to_string()) // Or return an error
    } else {
        format!("{}.s3.{}.amazonaws.com", bucket, self.name)
    }
}
```
This ensures that the host is extracted according to standard URL parsing rules, mitigating the risk of SSRF.

#### 15. Uncontrolled Search Path Element

- **Location:** `bin\gui\tray.rs` (lines 102-108)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-427

**Description:**
The `get_icon_path` function attempts to load icon resource files by first searching in the current working directory (`std::env::current_dir()`). The current working directory is an untrusted location that can be controlled by an attacker. If a user is tricked into running the application from a directory containing a malicious `icons/logo.png` or `icons/app_icon.ico` file, the application will load and parse the malicious file. This could lead to a denial-of-service or potentially arbitrary code execution if the image parsing library has a vulnerability that can be triggered by a malformed image file. Applications should only load resources from trusted, well-defined locations, such as the directory containing the application executable.

**Remediation:**
Remove the logic that searches for resources in the current working directory. The application should only load resources from a path relative to its own executable. The search order should be modified to only check the path derived from `std::env::current_exe()`.

```rust
// Recommended change for get_icon_path function

/// Gets the path to an icon file
fn get_icon_path(filename: &str) -> PathBuf {
    // The primary and safest location for resources is relative to the executable.
    if let Ok(exe_path) = std::env::current_exe() {
        if let Some(exe_dir) = exe_path.parent() {
            let icon_path = exe_dir.join("icons").join(filename);
            if icon_path.exists() {
                return icon_path;
            }
        }
    }

    // As a fallback for development environments, you can check the CWD,
    // but this should ideally be behind a debug flag.
    #[cfg(debug_assertions)]
    {
        if let Ok(current_dir) = std::env::current_dir() {
            let icon_path = current_dir.join("icons").join(filename);
            if icon_path.exists() {
                return icon_path;
            }
        }
    }

    // Fallback to just the filename, which might be resolved by the OS search path.
    // This is still potentially risky and should be avoided if possible.
    // A better fallback would be to embed the icon in the binary.
    PathBuf::from(filename)
}
```

#### 16. Sensitive Password Data Lingers in Memory

- **Location:** `volume\mount\mod.rs` (line 83)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-316

**Description:**
The `MountOptions` struct stores the `hidden_password` as a standard `Option<String>`, and the `mount` function accepts the main `password` as a `&str`. Standard string types in Rust are not guaranteed to be zeroed out from memory when they are dropped or go out of scope. This means the cleartext password may remain in the application's memory for an indeterminate amount of time. An attacker who can read the process's memory (e.g., through a core dump, debugging interfaces, or another vulnerability) could potentially recover these passwords.

**Remediation:**
Use a dedicated secret-handling type that securely zeroes its memory buffer on drop. The `secrecy` crate is a common and recommended choice in the Rust ecosystem for this purpose.

1.  Add the `secrecy` crate as a dependency to your project.
2.  Modify the `MountOptions` struct to use `secrecy::SecretString`:
    ```rust
    // Before
    pub hidden_password: Option<String>,

    // After
    use secrecy::{SecretString, ExposeSecret};
    pub hidden_password: Option<SecretString>,
    ```
3.  Modify the `mount` function signature to accept a secret-aware type for the password.
    ```rust
    // Before
    pub fn mount(
        container_path: impl AsRef<Path>,
        password: &str,
        options: MountOptions,
    ) -> Result<MountHandle> { ... }

    // After
    use secrecy::{SecretString, ExposeSecret};
    pub fn mount(
        container_path: impl AsRef<Path>,
        password: &SecretString,
        options: MountOptions,
    ) -> Result<MountHandle> {
        // When passing the password to the underlying functions, expose it
        // for the shortest possible duration.
        // e.g., fuse::mount(container_path, password.expose_secret(), options)
        ...
    }
    ```
This ensures that the password's memory is wiped as soon as the `SecretString` variable is dropped, significantly reducing the window of opportunity for memory-scraping attacks.

### ðŸŸ¢ Low (8)

#### 1. Integer Overflow in `increment` Can Cause Progress Wrap-Around

- **Location:** `progress.rs` (line 154)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-190

**Description:**
The `increment` method calculates the new `bytes_processed` value using `self.bytes_processed + delta`. In release builds, Rust's default behavior for integer arithmetic on primitive types is to wrap on overflow. If `self.bytes_processed` is close to `u64::MAX` (over 16 exabytes), adding a `delta` can cause the value to wrap around to a small number. This would cause the reported progress to suddenly drop from nearly 100% to nearly 0%, and the `is_complete()` method would switch from `true` to `false`. This violates the expected monotonic nature of progress reporting and could lead to logic errors or denial-of-service conditions in consuming code that relies on the `is_complete()` state to be final.

**Remediation:**
Use `saturating_add` to prevent the overflow. This will ensure that `bytes_processed` is capped at `u64::MAX` and the progress remains at or above 100% once that threshold is reached, which is the correct behavior for a progress tracker.

Change line 154 from:
`self.update(self.bytes_processed + delta);`
to:
`self.update(self.bytes_processed.saturating_add(delta));`

#### 2. Lack of Nonce Reuse Warning in `Encryptor` Trait Documentation

- **Location:** `crypto\mod.rs` (lines 34-46)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-329

**Description:**
The `Encryptor` trait defines an `encrypt` method that accepts a nonce provided by the caller. In most modern authenticated encryption (AEAD) ciphers, such as AES-GCM, reusing the same nonce with the same key to encrypt different plaintexts is catastrophic. It can lead to a complete loss of both confidentiality and authenticity.

The documentation for the `Encryptor` trait and its `encrypt` method does not explicitly warn developers about the critical importance of using a unique nonce for every encryption operation with a given key. This omission creates a "footgun" API, where consumers of the trait can easily misuse it in a way that introduces severe security vulnerabilities into their application.

**Remediation:**
Update the documentation for the `Encryptor` trait and its `encrypt` method to include a prominent security warning about the dangers of nonce reuse. The warning should clearly state that a given (key, nonce) pair must never be used more than once. It is also recommended to suggest strategies for nonce generation, such as using a counter or a cryptographically secure random number generator (CSPRNG).

Example of improved documentation:
```rust
    /// Encrypt plaintext with a given key and nonce.
    ///
    /// # Security Warning
    ///
    /// The `nonce` MUST be unique for every encryption operation performed with the same `key`.
    /// Reusing a (key, nonce) pair to encrypt different messages will completely destroy
    /// the security properties of the cipher, leading to a loss of confidentiality and authenticity.
    ///
    /// # Arguments
    ///
    /// * `key` - 32-byte encryption key
    /// * `nonce` - Nonce (size depends on algorithm, see `nonce_len()`)
    /// * `plaintext` - Data to encrypt
    ///
    /// # Returns
    ///
    /// Ciphertext with authentication tag appended.
    fn encrypt(&self, key: &[u8; 32], nonce: &[u8], plaintext: &[u8]) -> Result<Vec<u8>>;
```

#### 3. Sensitive Key Material Exposed as Raw Slice

- **Location:** `crypto\signatures.rs` (lines 118-120)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-200

**Description:**
The `signing_key_seed` function returns a raw byte slice (`&[u8; 32]`) of the secret seed. The internal seed is stored in a `Zeroizing` wrapper to ensure it is securely wiped from memory when it goes out of scope. By returning a raw slice, the function allows callers to easily copy the secret key material into regular memory that will not be zeroized. This undermines the security guarantee provided by the `Zeroizing` wrapper and could lead to the secret key persisting in memory longer than necessary, increasing its exposure to memory-scraping attacks or accidental logging.

**Remediation:**
The function should not return a raw slice that allows the secret to escape its protective container. A safer approach is to provide temporary, scoped access to the key material. Modify the function to accept a closure that operates on the secret slice, ensuring the reference to the secret cannot be stored or copied outside of the intended scope.

Example of a safer implementation:
```rust
/// Executes a closure with a temporary reference to the signing key seed.
///
/// This method ensures that the raw reference to the secret key material
/// does not escape the intended scope.
pub fn with_signing_key_seed<F, R>(&self, f: F) -> R
where
    F: FnOnce(&[u8; 32]) -> R,
{
    f(&self.seed)
}
```
If direct access is still required by the API, consider returning a cloned `Zeroizing` object instead of a raw slice, although this is less preferable than the closure-based approach.

#### 4. Logging of Sensitive Random Data in Test Function

- **Location:** `hsm\tpm.rs` (line 1505)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-532: Insertion of Sensitive Information into Log File

**Description:**
The test function `test_tpm_integration` logs the first 8 bytes of a 32-byte random number obtained from the TPM. While this occurs within a test environment, logging cryptographic material is a bad practice. If these test logs are stored, aggregated, or exposed (e.g., in public CI/CD pipelines), it could lead to an unnecessary information leak. The assertions on the following lines are sufficient to validate the functionality without exposing the generated value.

**Remediation:**
Remove the printing of the random bytes from the log message. The assertions that follow are sufficient for verifying the function's correctness. Change the line to `println!("TPM random ({} bytes) received successfully", random.len());` or a similar message that does not include the sensitive data.

#### 5. Insecure udev Rule Suggested in Documentation

- **Location:** `hsm\yubikey.rs` (line 25)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-732

**Description:**
The documentation in the file header suggests a udev rule (`SUBSYSTEM=="usb", ATTRS{idVendor}=="1050", MODE="0666"`) for granting access to the YubiKey device on Linux. The `MODE="0666"` permission is world-readable and world-writable, allowing any user on the system to access and interact with the YubiKey device. This could allow a malicious local user to interfere with authentication operations, potentially causing a denial of service or attempting to perform their own challenge-response operations.

**Remediation:**
Recommend a more secure udev rule that restricts access to a specific user or group. A better practice is to assign the device to a specific group (e.g., `plugdev`) and limit permissions. For example: `SUBSYSTEM=="usb", ATTRS{idVendor}=="1050", GROUP="plugdev", MODE="0660"`. This grants read/write access only to the root user and members of the `plugdev` group.

#### 6. Use of Outdated HMAC-SHA1 Algorithm

- **Location:** `hsm\yubikey.rs` (line 10)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-327

**Description:**
The module exclusively uses HMAC-SHA1 for the challenge-response mechanism. While HMAC as a construction is not broken by the collision attacks on SHA-1, the SHA-1 algorithm itself is considered deprecated and weak by modern cryptographic standards. Industry best practices (such as NIST SP 800-131A) recommend phasing out SHA-1 in favor of stronger algorithms from the SHA-2 family (e.g., SHA-256). Many YubiKey models support HMAC-SHA256. Continuing to use HMAC-SHA1 reduces the long-term security posture of the application and may not comply with modern security requirements.

**Remediation:**
Update the implementation to support and default to HMAC-SHA256. Add a configuration option to select the HMAC algorithm, defaulting to SHA-256. This would likely involve changing the `Mode::Sha1` setting on line 188 and ensuring the underlying `yubikey-hmac-otp` crate supports other modes. If the crate does not support stronger algorithms, consider migrating to a different one that does.

#### 7. Denial of Service via Panic on Poisoned Mutex

- **Location:** `memory\debugger.rs` (line 141)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-755

**Description:**
The `set_callback` function uses `self.callback.lock().unwrap()`. If the monitoring thread panics while holding the mutex lock (for example, if the user-provided callback panics), the mutex becomes "poisoned". A subsequent call to `set_callback` from another thread will then also panic due to the `unwrap()`, which can crash that thread or the entire application, leading to a denial of service. While the monitoring thread itself handles a poisoned mutex gracefully, this public-facing configuration method does not. An attacker cannot directly trigger this, but a faulty callback could put the `DebuggerMonitor` into a state where it causes other parts of the application to crash.

**Remediation:**
Handle the `Result` returned by `lock()` instead of using `unwrap()`. The function should either return a `Result` to the caller or handle the poisoned state by recovering the lock. Recovering is often acceptable if the data protected by the mutex is still in a valid state.

Example of recovering from a poisoned mutex:
```rust
pub fn set_callback(&mut self, callback: DebuggerCallback) {
    match self.callback.lock() {
        Ok(mut guard) => {
            *guard = Some(callback);
        }
        Err(poisoned) => {
            // Log the event and recover the lock, as the data is still usable.
            // A panic in the old callback doesn't corrupt the Option<DebuggerCallback>.
            eprintln!("Warning: DebuggerMonitor mutex was poisoned. Recovering.");
            let mut guard = poisoned.into_inner();
            *guard = Some(callback);
        }
    }
}
```

#### 8. Silent Fallback on Memory Locking Failure Violates Security Guarantee

- **Location:** `memory\pool.rs` (lines 192-196)
- **Tool:** gemini-ai
- **Confidence:** medium
- **CWE:** CWE-755

**Description:**
For `High` and `Maximum` security levels, the `allocate` function is expected to use locked memory to prevent sensitive data from being swapped to disk. The function's documentation (line 157) states it will return an error if memory locking fails. However, the implementation catches the error from `LockedMemory::new` and silently falls back to a "best-effort" non-locking implementation. This means an allocation can succeed without the memory actually being locked, violating the security guarantee promised by the `High` and `Maximum` levels without informing the caller. An application might proceed assuming the no-swap guarantee is in place when it is not.

**Remediation:**
The function should adhere to its documented contract. If `LockedMemory::new` fails, the `allocate` function should propagate the error and fail the allocation. If a fallback mechanism is desired, it should be explicitly documented and possibly require an opt-in from the caller, so they are aware of the reduced security posture.

## Findings by File

### `bin\gui\tray.rs` (1 medium)
- [MEDIUM] Uncontrolled Search Path Element L102

### `bin\register\mod.rs` (1 high)
- [HIGH] Privilege Escalation due to Insecure Relative Path Resolution L18

### `crypto\hardware.rs` (1 high)
- [HIGH] Use of a Static, All-Zero Nonce in AES-GCM Benchmark Functions L784

### `crypto\mod.rs` (1 low)
- [LOW] Lack of Nonce Reuse Warning in `Encryptor` Trait Documentation L34

### `crypto\pqc_tests.rs` (1 medium)
- [MEDIUM] Hardcoded Weak Password in Test Case L250

### `crypto\signatures.rs` (1 low)
- [LOW] Sensitive Key Material Exposed as Raw Slice L118

### `crypto\streaming.rs` (1 high)
- [HIGH] Plaintext Written to Output Before Final Integrity Verification L1544

### `daemon\client.rs` (1 medium)
- [MEDIUM] Authentication Token Clone Not Zeroized in Memory L177

### `error.rs` (1 medium)
- [MEDIUM] Excessive Information in Error Messages Can Leak Sensitive Data L15

### `hsm\mod.rs` (2 medium)
- [MEDIUM] Insecure Default Configuration for HSM L87
- [MEDIUM] Use of Weak Cryptographic Algorithm (HMAC-SHA1) L10

### `hsm\tpm.rs` (1 medium, 1 low)
- [MEDIUM] Support for Broken Cryptographic Algorithm (SHA-1) L1667
- [LOW] Logging of Sensitive Random Data in Test Function L1505

### `hsm\tpm_utils.rs` (1 medium)
- [MEDIUM] Use of a Cryptographically Weak Hashing Algorithm (SHA-1) L40

### `hsm\yubikey.rs` (1 medium, 2 low)
- [MEDIUM] Unenforced YubiKey Serial Number Allows Device Spoofing L93
- [LOW] Insecure udev Rule Suggested in Documentation L25
- [LOW] Use of Outdated HMAC-SHA1 Algorithm L10

### `hsm\yubikey_stub.rs` (1 medium)
- [MEDIUM] Use of Deprecated and Potentially Insecure Random Number Generator API L146

### `memory\debugger.rs` (1 low)
- [LOW] Denial of Service via Panic on Poisoned Mutex L141

### `memory\dump_protection.rs` (1 high)
- [HIGH] Ineffective Crash Dump Protection on Windows L127

### `memory\pool.rs` (1 critical, 1 medium, 1 low)
- [CRITICAL] Critical Nonce Reuse in `EncryptedAllocation::write` L282
- [MEDIUM] Use of Unauthenticated Encryption L36
- [LOW] Silent Fallback on Memory Locking Failure Violates Security Guarantee L192

### `progress.rs` (1 low)
- [LOW] Integer Overflow in `increment` Can Cause Progress Wrap-Around L154

### `volume\automount.rs` (1 medium)
- [MEDIUM] Sensitive Password Data Exposed in Memory L292

### `volume\cloud_sync.rs` (1 critical)
- [CRITICAL] Unauthenticated Remote Wipe Command Execution L934

### `volume\dropbox_client.rs` (1 medium)
- [MEDIUM] Path Traversal in Dropbox Path Prefix L105

### `volume\header.rs` (1 medium)
- [MEDIUM] Uncontrolled Memory Allocation via Deserialization Leading to Denial of Service L647

### `volume\manager.rs` (1 critical)
- [CRITICAL] Incorrect Password Used for Mounting Hidden Volumes L254

### `volume\mount\mod.rs` (1 medium)
- [MEDIUM] Sensitive Password Data Lingers in Memory L83

### `volume\s3_client.rs` (1 critical, 1 medium)
- [CRITICAL] Incorrect Implementation of AWS Signature V4 Using BLAKE3 Instead of HMAC-SHA256 L395
- [MEDIUM] Naive URL Parsing May Lead to Server-Side Request Forgery (SSRF) L138

### `wasm\security.rs` (1 high)
- [HIGH] CSP Injection via Unsanitized Whitespace in `additional_sources` L127

## Tools Used

| Tool | Description |
|------|-------------|
| bandit | Python security linter |
| semgrep | Multi-language static analysis |
| safety | Python dependency scanner |
| gemini | AI-powered code analysis |

---

*Report generated by CodeScanner on 2026-01-05 20:37:32*

**Disclaimer:** This automated scan may produce false positives or miss certain vulnerabilities.
Manual security review is recommended for critical applications.